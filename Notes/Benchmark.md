## Benchmark Notes

## System Specs

- CPU: Intel i5-12th Gen
- RAM: 16 GB
- OS: Windows 11

---

## Model Performance (CPU, Q4_K)

| Model | RAM Usage | Inference Speed | Observations |
|-------|-----------|----------------|--------------|
| DeepSeek-R1-Distill-Qwen-7B | ~7–8 GB | Moderate | Good reasoning/math |
| Mistral-7B-Instruct-v0.2 | ~6–7 GB | Slightly faster | General-purpose, creative tasks |

---

## Notes

- LM Studio local API is sufficient; Streamlit not required.
- For GPU: performance improves ~2–3x if supported.
- Q2_K for lighter RAM setups (~5 GB), Q5_K for better quality (~9–10 GB).
